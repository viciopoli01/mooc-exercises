{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/dtlogo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hope in this activity is to do initialization, predict update of the histogram filter but should be a template we can follow for the others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from complete_image_pipeline.pipeline import run_pipeline\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "import duckietown_code_utils as dtu\n",
    "from anti_instagram import AntiInstagramInterface\n",
    "from duckietown_msgs.msg import Segment, SegmentList\n",
    "from duckietown_segmaps import FRAME_AXLE, FRAME_GLOBAL\n",
    "from duckietown_segmaps.draw_map_on_images import plot_map, predict_segments\n",
    "from duckietown_segmaps.maps import plot_map_and_segments\n",
    "from duckietown_segmaps.transformations import TransformationsInfo\n",
    "from easy_algo import get_easy_algo_db\n",
    "from easy_node.utils.timing import FakeContext, ProcessingTimingStats\n",
    "from ground_projection.ground_projection_interface import find_ground_coordinates\n",
    "from ground_projection.segment import rectify_segments\n",
    "from image_processing.ground_projection_geometry import GroundProjectionGeometry\n",
    "from image_processing.rectification import Rectify\n",
    "from line_detector2.image_prep import ImagePrep\n",
    "from line_detector_interface import FAMILY_LINE_DETECTOR\n",
    "from line_detector_interface.visual_state_fancy_display import normalized_to_image, vs_fancy_display\n",
    "from localization_templates import FAMILY_LOC_TEMPLATES\n",
    "import duckietown_code_utils as dtu\n",
    "from image_processing.more_utils import get_robot_camera_geometry\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.stats import entropy, multivariate_normal\n",
    "from math import floor, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "img = cv2.imread(\"images/pic1.png\")\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_detector_name=\"baseline\"\n",
    "image_prep_name=\"baseline\"\n",
    "anti_instagram_name=\"baseline\"\n",
    "robot_name = \"lab\"\n",
    "rcg = get_robot_camera_geometry(robot_name)\n",
    "\n",
    "dtu.check_isinstance(img, np.ndarray)\n",
    "\n",
    "algo_db = get_easy_algo_db()\n",
    "line_detector = algo_db.create_instance(FAMILY_LINE_DETECTOR, line_detector_name)\n",
    "image_prep = algo_db.create_instance(ImagePrep.FAMILY, image_prep_name)\n",
    "ai = algo_db.create_instance(AntiInstagramInterface.FAMILY, anti_instagram_name)\n",
    "segment_list = image_prep.process(FakeContext(), img, line_detector, transform=None)\n",
    "jpg1 = vs_fancy_display(image_prep.image_cv, segment_list)\n",
    "\n",
    "imshow(jpg1)\n",
    "\n",
    "segment_list_rect = rectify_segments(rcg.rectifier, rcg.gpg , segment_list)\n",
    "\n",
    "sg = find_ground_coordinates(rcg.gpg, segment_list_rect)\n",
    "\n",
    "#res, _stats = run_pipeline(\n",
    "#        img,\n",
    "#        gpg=rcg.gpg,\n",
    "#        rectifier=rcg.rectifier,\n",
    "#        line_detector_name=line_detector_name,\n",
    "#        image_prep_name=image_prep_name,\n",
    "#        lane_filter_name=lane_filter_name,\n",
    "#        anti_instagram_name=anti_instagram_name,\n",
    "#        all_details=True,\n",
    "#        ground_truth=None,\n",
    "#)\n",
    "\n",
    "outd = \"output\"\n",
    "#dtu.write_jpgs_to_dir(res, outd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parameters from the configuration file\n",
    "import yaml\n",
    "with open(\"src/lane_filter/config/lane_filter_node/default.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        params = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "hp = params[\"lane_filter_histogram_configuration\"]\n",
    "print(hp)\n",
    "\n",
    "d, phi = np.mgrid[hp['d_min'] : hp['d_max'] : hp['delta_d'], hp['phi_min'] : hp['phi_max'] : hp['delta_phi']]\n",
    "grid_spec = {\n",
    "    \"d\": d,\n",
    "    \"phi\": phi,\n",
    "    \"delta_d\": hp['delta_d'],\n",
    "    \"delta_phi\": hp['delta_phi'],\n",
    "    \"d_min\": hp['d_min'],\n",
    "    \"d_max\": hp['d_max'],\n",
    "    \"phi_min\": hp['phi_min'],\n",
    "    \"phi_max\": hp['phi_max'],\n",
    "}\n",
    "road_spec = {\n",
    "    \"linewidth_white\": hp['linewidth_white'],\n",
    "    \"linewidth_yellow\": hp['linewidth_yellow'],\n",
    "    \"lanewidth\": hp['lanewidth'],\n",
    "}\n",
    "robot_spec = {\n",
    "    \"wheel_radius\": hp['wheel_radius'],\n",
    "    \"wheel_baseline\": hp['wheel_baseline'],\n",
    "    \"encoder_resolution\": hp['encoder_resolution'],\n",
    "}\n",
    "# The \"cov_mask\" is effectively the process model covariance\n",
    "cov_mask = [hp['sigma_d_mask'], hp['sigma_phi_mask']]\n",
    "belief = np.empty(d.shape)\n",
    "mean_0 = [hp['mean_d_0'], hp['mean_phi_0']]\n",
    "cov_0 = [[hp['sigma_d_0'], 0], [0, hp['sigma_phi_0']]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def histogram_prior(belief, grid_spec, mean_0, cov_0):\n",
    "    pos = np.empty(belief.shape + (2,))\n",
    "    pos[:, :, 0] = grid_spec[\"d\"]\n",
    "    pos[:, :, 1] = grid_spec[\"phi\"]\n",
    "    RV = multivariate_normal(mean_0, cov_0)\n",
    "    belief = RV.pdf(pos)\n",
    "    return belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def histogram_predict(belief, dt, left_encoder_ticks, right_encoder_ticks, grid_spec, robot_spec, cov_mask):\n",
    "        belief_in = belief\n",
    "        delta_t = dt\n",
    "        # TODO calculate v and w from ticks using kinematics. You will need `robot_spec`\n",
    "        v = 0.0\n",
    "        w = 0.0\n",
    "        d_t = grid_spec['d'] + v * delta_t * np.sin(grid_spec['phi'])\n",
    "        phi_t = grid_spec['phi'] + w * delta_t\n",
    "\n",
    "        p_belief = np.zeros(belief.shape)\n",
    "\n",
    "        # histogram propagation step\n",
    "        for i in range(belief.shape[0]):\n",
    "            for j in range(belief.shape[1]):\n",
    "                if belief[i, j] > 0:\n",
    "                    if (\n",
    "                        d_t[i, j] > grid_spec['d_max']\n",
    "                        or d_t[i, j] < grid_spec['d_min']\n",
    "                        or phi_t[i, j] < grid_spec['phi_min']\n",
    "                        or phi_t[i, j] > grid_spec['phi_max']\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    i_new = int(floor((d_t[i, j] - grid_spec['d_min']) / grid_spec['delta_d']))\n",
    "                    j_new = int(floor((phi_t[i, j] - grid_spec['phi_min']) / grid_spec['delta_phi']))\n",
    "\n",
    "                    p_belief[i_new, j_new] += belief[i, j]\n",
    "\n",
    "        s_belief = np.zeros(belief.shape)\n",
    "        gaussian_filter(p_belief, cov_mask, output=s_belief, mode=\"constant\")\n",
    "\n",
    "        if np.sum(s_belief) == 0:\n",
    "            return belief_in\n",
    "        belief = s_belief / np.sum(s_belief)\n",
    "        return belief\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def prepare_segments(segments):\n",
    "    filtered_segments = []\n",
    "    for segment in segments:\n",
    "\n",
    "        # we don't care about RED ones for now\n",
    "        if segment.color != segment.WHITE and segment.color != segment.YELLOW:\n",
    "            continue\n",
    "        # filter out any segments that are behind us\n",
    "        if segment.points[0].x < 0 or segment.points[1].x < 0:\n",
    "            continue\n",
    "\n",
    "        filtered_segments.append(segment)\n",
    "    return filtered_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def generate_vote(segment, road_spec):\n",
    "    p1 = np.array([segment.points[0].x, segment.points[0].y])\n",
    "    p2 = np.array([segment.points[1].x, segment.points[1].y])\n",
    "    t_hat = (p2 - p1) / np.linalg.norm(p2 - p1)\n",
    "\n",
    "    n_hat = np.array([-t_hat[1], t_hat[0]])\n",
    "    d1 = np.inner(n_hat, p1)\n",
    "    d2 = np.inner(n_hat, p2)\n",
    "    l1 = np.inner(t_hat, p1)\n",
    "    l2 = np.inner(t_hat, p2)\n",
    "    if l1 < 0:\n",
    "        l1 = -l1\n",
    "    if l2 < 0:\n",
    "        l2 = -l2\n",
    "\n",
    "    l_i = (l1 + l2) / 2\n",
    "    d_i = (d1 + d2) / 2\n",
    "    phi_i = np.arcsin(t_hat[1])\n",
    "    if segment.color == segment.WHITE:  # right lane is white\n",
    "        if p1[0] > p2[0]:  # right edge of white lane\n",
    "            d_i -= road_spec['linewidth_white']\n",
    "        else:  # left edge of white lane\n",
    "            d_i = -d_i\n",
    "            phi_i = -phi_i\n",
    "        d_i -= road_spec['lanewidth'] / 2\n",
    "\n",
    "    elif segment.color == segment.YELLOW:  # left lane is yellow\n",
    "        if p2[0] > p1[0]:  # left edge of yellow lane\n",
    "            d_i -= road_spec['linewidth_yellow']\n",
    "            phi_i = -phi_i\n",
    "        else:  # right edge of white lane\n",
    "            d_i = -d_i\n",
    "        d_i = road_spec['lanewidth'] / 2 - d_i\n",
    "\n",
    "    return d_i, phi_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def generate_measurement_likelihood(segments, road_spec, grid_spec):\n",
    "\n",
    "    # initialize measurement likelihood to all zeros\n",
    "    measurement_likelihood = np.zeros(grid_spec['d'].shape)\n",
    "\n",
    "    for segment in segments:\n",
    "        d_i, phi_i = generate_vote(segment, road_spec)\n",
    "\n",
    "        # if the vote lands outside of the histogram discard it\n",
    "        if d_i > grid_spec['d_max'] or d_i < grid_spec['d_min'] or phi_i < grid_spec['phi_min'] or phi_i > grid_spec['phi_max']:\n",
    "            continue\n",
    "\n",
    "        i = int(floor((d_i - grid_spec['d_min']) / grid_spec['delta_d']))\n",
    "        j = int(floor((phi_i - grid_spec['phi_min']) / grid_spec['delta_phi']))\n",
    "        measurement_likelihood[i, j] += 1\n",
    "\n",
    "    if np.linalg.norm(measurement_likelihood) == 0:\n",
    "        return None\n",
    "    measurement_likelihood /= np.sum(measurement_likelihood)\n",
    "    return measurement_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def histogram_update(belief, segments, road_spec, grid_spec):\n",
    "    # prepare the segments for each belief array\n",
    "    segmentsArray = prepare_segments(segments)\n",
    "    # generate all belief arrays\n",
    "\n",
    "    measurement_likelihood = generate_measurement_likelihood(segmentsArray, road_spec, grid_spec)\n",
    "\n",
    "    if measurement_likelihood is not None:\n",
    "        belief = np.multiply(belief, measurement_likelihood)\n",
    "        if np.sum(belief) == 0:\n",
    "            belief = measurement_likelihood\n",
    "        else:\n",
    "            belief /= np.sum(belief)\n",
    "    return (measurement_likelihood, belief)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1 #s\n",
    "left = 10 # left ticks\n",
    "right = 20 # right ticks\n",
    "\n",
    "belief = histogram_prior(belief, grid_spec, mean_0, cov_0)\n",
    "imshow(belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belief = histogram_predict(belief, dt, left, right, grid_spec, robot_spec, cov_mask)\n",
    "imshow(belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(measurement_likelihood, belief) = histogram_update(belief,sg.segments, road_spec, grid_spec)\n",
    "imshow(belief)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
